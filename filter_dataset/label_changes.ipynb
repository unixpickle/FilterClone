{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label changes\n",
    "\n",
    "A simple workflow to label if a Snapchat lens has actually changed an image or not.\n",
    "This can be used to build up a small dataset (a few hundred images) for train_change_clf.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/MLData2/laion-icons-selfies/filtered/download\"\n",
    "output_dir = \"/Volumes/MLData2/outputs/cartoon_kid\"\n",
    "label_dir = 'change_labeled_cartoon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(name):\n",
    "    img1 = Image.open(os.path.join(input_dir, name)).convert('RGB')\n",
    "    img2 = Image.open(os.path.join(output_dir, name)).convert('RGB')\n",
    "    return img1, img2\n",
    "\n",
    "def side_by_side(name):\n",
    "    img1, img2 = load_images(name)\n",
    "    result = Image.fromarray(np.concatenate([np.array(img1), np.array(img2)], axis=1))\n",
    "    result.thumbnail((512, 512))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label(name, label):\n",
    "    os.makedirs(os.path.join(label_dir, name))\n",
    "    with open(os.path.join(label_dir, name, 'label.json'), 'w') as f:\n",
    "        json.dump(label, f)\n",
    "    shutil.copyfile(os.path.join(input_dir, name), os.path.join(label_dir, name, 'input.png'))\n",
    "    shutil.copyfile(os.path.join(output_dir, name), os.path.join(label_dir, name, 'output.png'))\n",
    "\n",
    "def unlabel(name):\n",
    "    shutil.rmtree(os.path.join(label_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_names = os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_name = None\n",
    "for name in out_names:\n",
    "    if os.path.exists(os.path.join(label_dir, name)):\n",
    "        continue\n",
    "    try:\n",
    "        display(side_by_side(name))\n",
    "    except:\n",
    "        continue\n",
    "    while True:\n",
    "        label = input('Did the filter work? y/n:').strip()\n",
    "        if label == 'y':\n",
    "            save_label(name, True)\n",
    "        elif label == 'n':\n",
    "            save_label(name, False)\n",
    "        elif label == 'x':\n",
    "            print('deleting', prev_name)\n",
    "            unlabel(prev_name)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "        prev_name = name\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layers = nn.Sequential(\n",
    "            nn.Conv2d(6, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layers = nn.Sequential(\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def apply_to_pair(self, img1: Image.Image, img2: Image.Image) -> torch.Tensor:\n",
    "        img1 = img1.convert('RGB')\n",
    "        img2 = img2.convert('RGB')\n",
    "        img1.thumbnail((256, 256))\n",
    "        img2.thumbnail((256, 256))\n",
    "        arr = np.concatenate([np.array(img1), np.array(img2)], axis=-1)\n",
    "        tensor = torch.from_numpy(arr).permute(2, 0, 1)[None].float() / 127.5 - 1\n",
    "        return self(tensor)\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        spatial_out = self.in_layers(images)\n",
    "        spatial_out = spatial_out.flatten(2).mean(-1)\n",
    "        return self.out_layers(spatial_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(name: str) -> tuple[Image.Image, Image.Image, bool]:\n",
    "    img1 = Image.open(os.path.join(label_dir, name, 'input.png'))\n",
    "    img2 = Image.open(os.path.join(label_dir, name, 'output.png'))\n",
    "    with open(os.path.join(label_dir, name, 'label.json'), 'r') as f:\n",
    "        label = json.load(f)\n",
    "    return img1, img2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [x for x in os.listdir(label_dir) if not x.startswith('.')]\n",
    "random.shuffle(names)\n",
    "num_test = 40\n",
    "train_names = names[num_test:]\n",
    "test_names = names[:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(model, name: str) -> torch.Tensor:\n",
    "    img1, img2, label = load_pair(name)\n",
    "    pred = model.apply_to_pair(img1, img2)\n",
    "    return (\n",
    "        F.binary_cross_entropy_with_logits(pred[0], torch.tensor([float(label)])),\n",
    "        (pred.item() > 0) == label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "os.makedirs('ckpt_cartoon', exist_ok=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_losses, train_corr = [], []\n",
    "    for name in tqdm(train_names):\n",
    "        img1, img2, label = load_pair(name)\n",
    "        loss, correct = eval_loss(model, name)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_losses.append(loss.item())\n",
    "        train_corr.append(correct)\n",
    "    test_losses, test_corr = [], []\n",
    "    for name in tqdm(test_names):\n",
    "        with torch.no_grad():\n",
    "            loss, correct = eval_loss(model, name)\n",
    "            test_losses.append(loss.item())\n",
    "            test_corr.append(correct)\n",
    "    print(f'epoch {epoch}: test_acc={np.mean(test_corr)} train_acc={np.mean(train_corr)} test_loss={np.mean(test_losses)} train_loss={np.mean(train_losses)}')\n",
    "    with open(f'ckpt_cartoon/model_{epoch}.pt', 'wb') as f:\n",
    "        torch.save(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load('ckpt/model_99.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in tqdm(names):\n",
    "    _, correct = eval_loss(name)\n",
    "    if not correct:\n",
    "        print('name', name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
